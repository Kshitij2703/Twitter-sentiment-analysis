{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4140,"sourceType":"datasetVersion","datasetId":2477}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport nltk\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\n# Download only essential NLTK data\nprint(\"Downloading NLTK data...\")\ntry:\n    nltk.download('punkt', quiet=True)\n    nltk.download('stopwords', quiet=True)\nexcept Exception as e:\n    print(f\"Warning: NLTK download failed - {str(e)}\")\n    print(\"Continuing with basic preprocessing...\")\n\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T05:35:31.104189Z","iopub.execute_input":"2024-10-29T05:35:31.104602Z","iopub.status.idle":"2024-10-29T05:35:31.112467Z","shell.execute_reply.started":"2024-10-29T05:35:31.104564Z","shell.execute_reply":"2024-10-29T05:35:31.111572Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Downloading NLTK data...\n","output_type":"stream"}]},{"cell_type":"code","source":"def load_data(file_path):\n    \"\"\"Load and prepare the dataset.\"\"\"\n    columns = ['target', 'id', 'date', 'flag', 'user', 'text']\n    df = pd.read_csv(file_path, encoding='latin-1', names=columns)\n    df['target'] = df['target'].map({0: 0, 4: 1})\n    return df[['text', 'target']]\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T05:35:40.536821Z","iopub.execute_input":"2024-10-29T05:35:40.537679Z","iopub.status.idle":"2024-10-29T05:35:40.542935Z","shell.execute_reply.started":"2024-10-29T05:35:40.537637Z","shell.execute_reply":"2024-10-29T05:35:40.541953Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def preprocess_text(text):\n    \"\"\"Clean and preprocess text data without lemmatization.\"\"\"\n    try:\n        # Basic cleaning\n        text = str(text).lower().strip()\n        \n        # Remove URLs\n        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n        \n        # Remove user mentions and hashtags\n        text = re.sub(r'@\\w+', '', text)\n        text = re.sub(r'#\\w+', '', text)\n        \n        # Remove special characters and digits\n        text = re.sub(r'[^\\w\\s]', '', text)\n        text = re.sub(r'\\d+', '', text)\n        \n        # Remove extra whitespace\n        text = ' '.join(text.split())\n        \n        # Tokenization\n        tokens = word_tokenize(text)\n        \n        # Remove stopwords if available\n        stop_words = set(stopwords.words('english'))\n        tokens = [token for token in tokens if token not in stop_words]\n        \n        return ' '.join(tokens)\n    except Exception as e:\n        print(f\"Error in preprocessing: {str(e)}\")\n        return text\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T05:35:49.602154Z","iopub.execute_input":"2024-10-29T05:35:49.602974Z","iopub.status.idle":"2024-10-29T05:35:49.611013Z","shell.execute_reply.started":"2024-10-29T05:35:49.602931Z","shell.execute_reply":"2024-10-29T05:35:49.610015Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def create_pipeline(file_path, sample_size=None):\n    \"\"\"Create and train the sentiment analysis pipeline.\"\"\"\n    print(\"Loading data...\")\n    df = load_data(file_path)\n    \n    if sample_size:\n        df = df.sample(n=sample_size, random_state=42)\n    \n    print(f\"Processing {len(df)} tweets...\")\n    \n    # Process in batches\n    batch_size = 10000\n    total_batches = len(df) // batch_size + 1\n    processed_texts = []\n    \n    for i in range(0, len(df), batch_size):\n        batch = df['text'].iloc[i:i+batch_size]\n        processed_batch = [preprocess_text(text) for text in batch]\n        processed_texts.extend(processed_batch)\n        \n        batch_num = i // batch_size + 1\n        print(f\"Processed batch {batch_num}/{total_batches}\")\n    \n    df['processed_text'] = processed_texts\n    \n    # Split the data\n    X_train, X_test, y_train, y_test = train_test_split(\n        df['processed_text'],\n        df['target'],\n        test_size=0.2,\n        random_state=42\n    )\n    \n    print(\"Vectorizing texts...\")\n    vectorizer = TfidfVectorizer(\n        max_features=10000,\n        ngram_range=(1, 2),\n        min_df=5\n    )\n    X_train_vectors = vectorizer.fit_transform(X_train)\n    X_test_vectors = vectorizer.transform(X_test)\n    \n    print(\"Training model...\")\n    model = LogisticRegression(max_iter=1000, C=1.0, class_weight='balanced')\n    model.fit(X_train_vectors, y_train)\n    \n    # Evaluate\n    y_pred = model.predict(X_test_vectors)\n    print(\"\\nClassification Report:\")\n    print(classification_report(y_test, y_pred))\n    \n    return vectorizer, model\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T05:35:59.502407Z","iopub.execute_input":"2024-10-29T05:35:59.502776Z","iopub.status.idle":"2024-10-29T05:35:59.513329Z","shell.execute_reply.started":"2024-10-29T05:35:59.502738Z","shell.execute_reply":"2024-10-29T05:35:59.512136Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def predict_sentiment(text, vectorizer, model):\n    \"\"\"Predict sentiment for new text.\"\"\"\n    processed_text = preprocess_text(text)\n    text_vector = vectorizer.transform([processed_text])\n    prediction = model.predict(text_vector)[0]\n    probability = model.predict_proba(text_vector)[0]\n    \n    sentiment = \"Positive\" if prediction == 1 else \"Negative\"\n    confidence = probability[1] if prediction == 1 else probability[0]\n    \n    return {\n        'sentiment': sentiment,\n        'confidence': confidence,\n        'processed_text': processed_text\n    }\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T05:36:07.305192Z","iopub.execute_input":"2024-10-29T05:36:07.306205Z","iopub.status.idle":"2024-10-29T05:36:07.313251Z","shell.execute_reply.started":"2024-10-29T05:36:07.306153Z","shell.execute_reply":"2024-10-29T05:36:07.312144Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    file_path = \"/kaggle/input/sentiment140/training.1600000.processed.noemoticon.csv\"\n    \n    # For testing with a smaller sample\n    vectorizer, model = create_pipeline(file_path, sample_size=100000)\n    \n    # Test the model\n    test_texts = [\n        \"I love this product! It's amazing!\",\n        \"This is the worst experience ever.\",\n        \"The weather is nice today.\"\n    ]\n    \n    print(\"\\nExample Predictions:\")\n    for text in test_texts:\n        result = predict_sentiment(text, vectorizer, model)\n        print(f\"\\nText: {text}\")\n        print(f\"Sentiment: {result['sentiment']}\")\n        print(f\"Confidence: {result['confidence']:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T05:36:34.505668Z","iopub.execute_input":"2024-10-29T05:36:34.506350Z","iopub.status.idle":"2024-10-29T05:37:16.023563Z","shell.execute_reply.started":"2024-10-29T05:36:34.506310Z","shell.execute_reply":"2024-10-29T05:37:16.022583Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Loading data...\nProcessing 100000 tweets...\nProcessed batch 1/11\nProcessed batch 2/11\nProcessed batch 3/11\nProcessed batch 4/11\nProcessed batch 5/11\nProcessed batch 6/11\nProcessed batch 7/11\nProcessed batch 8/11\nProcessed batch 9/11\nProcessed batch 10/11\nVectorizing texts...\nTraining model...\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.78      0.75      0.76      9995\n           1       0.76      0.78      0.77     10005\n\n    accuracy                           0.77     20000\n   macro avg       0.77      0.77      0.77     20000\nweighted avg       0.77      0.77      0.77     20000\n\n\nExample Predictions:\n\nText: I love this product! It's amazing!\nSentiment: Positive\nConfidence: 0.94\n\nText: This is the worst experience ever.\nSentiment: Negative\nConfidence: 0.75\n\nText: The weather is nice today.\nSentiment: Positive\nConfidence: 0.61\n","output_type":"stream"}]}]}